{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66df7e76-1cea-4baf-833d-a344cf94893e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# necessary libraries\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras import layers\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c911b8-c34e-4578-88f5-27788a178e2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# no need to execute this for me , i already execute it and i have folders of train and valitons sets\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# /kaggle/input/butterfly-image-classification/train/Image_4378.jpg'\n",
    "\n",
    "# Read the CSV file (assuming the columns are named \"filename\" and \"label\" by default)\n",
    "csv_file_path = \"C:/Users/MaestroCom/CNN/Training_set.csv\"\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Creating train and validation directories\n",
    "root_directory = \"C:/Users/MaestroCom/CNN\"  # Replace with your root directory name\n",
    "\n",
    "image_dir=\"C:/Users/MaestroCom/CNN/train\" \n",
    "\n",
    "train_directory = os.path.join(root_directory, \"train\")\n",
    "val_directory = os.path.join(root_directory, \"validation\")\n",
    "\n",
    "os.makedirs(train_directory, exist_ok=True)\n",
    "os.makedirs(val_directory, exist_ok=True)\n",
    "\n",
    "# Creating label directories\n",
    "labels = data[\"label\"].value_counts().index\n",
    "\n",
    "\n",
    "for label in labels:\n",
    "    label_train_directory = os.path.join(train_directory, label)\n",
    "    label_val_directory = os.path.join(val_directory, label)\n",
    "    os.makedirs(label_train_directory, exist_ok=True)\n",
    "    os.makedirs(label_val_directory, exist_ok=True)\n",
    "\n",
    "# Shuffle the data\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "# Split the data into 70% train and 30% validation\n",
    "val_data_count = int(len(data) * 0.3)\n",
    "validation_data = data[:val_data_count]\n",
    "train_data = data[val_data_count:]\n",
    "\n",
    "\n",
    "# Copy train data\n",
    "for index, row in train_data.iterrows():\n",
    "\n",
    "    # file name \n",
    "    file_name = row['filename']\n",
    "    # label name\n",
    "    label = row[\"label\"]\n",
    "\n",
    "    # images folder , all images are in here  \n",
    "    source_path = os.path.join(image_dir,file_name) #\n",
    "    # new destination\n",
    "    destination_directory = os.path.join(train_directory, label)\n",
    "    # copy files\n",
    "    shutil.copy(source_path, destination_directory)\n",
    "   \n",
    "    \n",
    "# Copy validation data\n",
    "for index, row in validation_data.iterrows():\n",
    " \n",
    "    file_name = row['filename']\n",
    "    label = row['label']\n",
    "    \n",
    "    source_path = os.path.join(image_dir, file_name)\n",
    "    destination_directory = os.path.join(val_directory, label)\n",
    "    shutil.copy(source_path, destination_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d072610-5c52-43f3-aa0d-a57c2c49f0f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#C:/Users/MaestroCom/proyek kelas work\n",
    "#os.listdir(\"C:/Users/MaestroCom/proyek kelas work/train/POPINJAY\")[:5]\n",
    "os.listdir(\"C:/Users/MaestroCom/CNN/train/POPINJAY\")[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66eddfe-de99-442b-b376-c9a47136c942",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.listdir(\"C:/Users/MaestroCom/CNN/validation/POPINJAY\")[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5ab876-214e-4a80-a446-6cc5d0be52ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#directories\n",
    "training_dir=\"C:/Users/MaestroCom/CNN/train\"\n",
    "validation_dir=\"C:/Users/MaestroCom/CNN/validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171b4e44-c7e2-4ae0-8f5c-4794321416a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# directories\n",
    "train_dir = training_dir\n",
    "validation_dir = validation_dir\n",
    "\n",
    "# calculate distribution of classes for train\n",
    "train_class_counts = {}\n",
    "for class_folder in os.listdir(train_dir):\n",
    "    class_path = os.path.join(train_dir, class_folder)\n",
    "    if os.path.isdir(class_path):\n",
    "        num_images = len(os.listdir(class_path))\n",
    "        train_class_counts[class_folder] = num_images\n",
    "\n",
    "# calculate distribution of classes for valdiation\n",
    "validation_class_counts = {}\n",
    "for class_folder in os.listdir(validation_dir):\n",
    "    class_path = os.path.join(validation_dir, class_folder)\n",
    "    if os.path.isdir(class_path):\n",
    "        num_images = len(os.listdir(class_path))\n",
    "        validation_class_counts[class_folder] = num_images\n",
    "\n",
    "print(\"Training set Distribution:\")\n",
    "print(train_class_counts)\n",
    "\n",
    "print(\"Validation set Distribution:\")\n",
    "print(validation_class_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde89eef-b750-4923-b83a-b5265e1dbf10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(train_class_counts.keys(), train_class_counts.values())\n",
    "plt.title('Training set Distribution')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Sample Numbers')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(validation_class_counts.keys(), validation_class_counts.values())\n",
    "plt.title('Validation set Distribution')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Sample Numbers')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dee8267-7ff5-49a0-91ba-8c7871aba0b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use this function for preparing data  \n",
    "def prep_data(augmented,batch_size=16):      # if you want to augmented dat set use it like this : prep_data(True)\n",
    "    if augmented:                            # default batch_size is 16 , you can change it \n",
    "        train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            rotation_range=40,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True)\n",
    "    \n",
    "        validation_datagen = ImageDataGenerator(rescale=1./255)    \n",
    "\n",
    "    else:\n",
    "        train_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "        validation_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "\n",
    "    # training set\n",
    "    train_set = train_datagen.flow_from_directory(\n",
    "        training_dir,\n",
    "        target_size=(180, 180),  # The dimensions to which all images found will be resized\n",
    "        batch_size=batch_size,# 32  default\n",
    "        class_mode=\"sparse\") # you can change this to onehotEncoded format or another format\n",
    "         \n",
    "    \n",
    "    # validation set\n",
    "    validation_set = validation_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(180, 180),\n",
    "        batch_size=batch_size,  # 32 default\n",
    "        class_mode=\"sparse\")\n",
    "             \n",
    "    return train_set , validation_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479eb8b1-5e11-4c62-a437-0de602251e38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visulization function for Models\n",
    "def visualize(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    axs[0].plot(epochs, acc, 'r', label='Training acc')\n",
    "    axs[0].plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    axs[0].set_title('Training and validation accuracy')\n",
    "    axs[0].legend()\n",
    "    axs[0].grid(True)\n",
    "    \n",
    "    axs[1].plot(epochs, loss, 'r', label='Training loss')\n",
    "    axs[1].plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    axs[1].set_title('Training and validation loss')\n",
    "    axs[1].legend()\n",
    "    axs[1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8724817f-ae12-478d-a636-03472b4f26f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# not augmented dataset\n",
    "#straight_train_set,validation_set=prep_data(False)\n",
    "\n",
    "#images,labels=straight_train_set.next()\n",
    "\n",
    "#class_names = straight_train_set.class_indices\n",
    "#class_names = {v: k for k, v in class_names.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953ce483-2173-4b5f-8a97-64a211c4c84c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# not augmented dataset\n",
    "straight_train_set, validation_set = prep_data(False)\n",
    "\n",
    "# Iterate over the batches of images and labels\n",
    "for images, labels in straight_train_set:\n",
    "    # Process the batch\n",
    "    # ...\n",
    "    break  # exit the loop after the first batch\n",
    "\n",
    "class_names = straight_train_set.class_indices\n",
    "class_names = {v: k for k, v in class_names.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca49894-139f-4b53-a4c7-2d607e2c91a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(15, 5))\n",
    "\n",
    "for i in range(4):\n",
    "    axes[i].imshow(images[i]) \n",
    "    label_index = int(labels[i])\n",
    "    class_name = class_names[label_index]\n",
    "    axes[i].set_title(f\"{class_name}\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2776f947-26ab-4508-85bc-9d53ddb02f43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# augmented dataset\n",
    "#augmented_train_set,validation_set=prep_data(True)\n",
    "#images,labels=augmented_train_set.next()\n",
    "\n",
    "#class_names = augmented_train_set.class_indices\n",
    "#class_names = {v: k for k, v in class_names.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bb92d6-7ef2-4b21-8051-f6f5eaa3541e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# augmented dataset\n",
    "augmented_train_set, validation_set = prep_data(True)\n",
    "\n",
    "# Get the batch size\n",
    "batch_size = augmented_train_set.batch_size\n",
    "\n",
    "# Iterate over the batches of images and labels\n",
    "for i in range(augmented_train_set.samples // batch_size):\n",
    "    images, labels = next(iter(augmented_train_set))\n",
    "    # Process the batch\n",
    "    # ...\n",
    "    break  # exit the loop after the first batch\n",
    "\n",
    "class_names = augmented_train_set.class_indices\n",
    "class_names = {v: k for k, v in class_names.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7ee4a4-8bf1-4aab-bb4d-a517dd6f8447",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(15, 5))\n",
    "\n",
    "for i in range(4):\n",
    "    axes[i].imshow(images[i]) \n",
    "    label_index = int(labels[i])\n",
    "    class_name = class_names[label_index]\n",
    "    axes[i].set_title(f\"{class_name}\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd29171-dcd5-4e4c-8939-ad6e98dfe3c5",
   "metadata": {},
   "source": [
    "#### cnn model 1_!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe3a3af-f965-4068-94d9-4af60c9bb46b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set,validation_set=prep_data(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410a4635-376a-44b5-9ef8-6be9f3a3d31b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(180, 180, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(75 , activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00404d3a-88c8-4325-bb0a-310beeb56b2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=2e-4),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb38d28a-4a0f-485f-9f40-abc734e58ee5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "\n",
    "# Define the model architecture\n",
    "#model = tf.keras.models.Sequential([\n",
    "    # Add layers to the model\n",
    "    # ...\n",
    "#])\n",
    "\n",
    "# Compile the model\n",
    "#model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=2e-4),\n",
    "              #loss='sparse_categorical_crossentropy',\n",
    "              #metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082fdfc5-858a-4437-97bb-482303397bc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1_1 = model.fit(\n",
    "    train_set,\n",
    "    epochs=30,\n",
    "    validation_data=validation_set,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f4a69b-467d-45fb-85a4-7c6ae9bc6e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(model1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbcb327-6344-495a-8d28-90696659492c",
   "metadata": {},
   "source": [
    "#### CNN MODEL 1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb454e4f-ef27-467b-b500-af3e1f434e79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(180, 180, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(75 , activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505f70a0-8251-4afa-8a0b-3c3c9b8067c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=2e-4),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4851f645-2cdf-4b73-8980-d608ece9d06c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1_1 = model.fit(\n",
    "    train_set,\n",
    "    epochs=50,\n",
    "    validation_data=validation_set,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17120d45-8828-4381-ad35-921e1a540947",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize(model1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90139add-a4ac-480a-9288-455d611eee85",
   "metadata": {},
   "source": [
    "#### Model 1_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5d61ff-35f6-45ec-9e5b-8ed5c6c08f21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set,validation_set=prep_data(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba3f472-57a0-40dc-908e-0e2a1f687dc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(180, 180, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(75 , activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246210b2-a3df-48fd-87a7-96d607665c33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001), # 0.0002\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853e253d-8432-4ffc-8ad8-198fcd8e8c25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1_3 = model.fit(\n",
    "    train_set,\n",
    "    epochs=100,\n",
    "    validation_data=validation_set,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ae6b0d-e3bd-4c92-8cfe-e662d32dddb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize(model1_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f0f353-f6e8-418c-b1bb-a241446b381a",
   "metadata": {},
   "source": [
    "#### Model 1_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab71ab6-eaf6-40b4-b88d-fec51a2be17e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set,validation_set=prep_data(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2c0f86-d23a-49df-9d30-7f47cdb92038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(180, 180, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(75 , activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff582b6-cf9e-478e-8674-e797a1508b68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001), # 0.0002\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a0404d-9016-4604-9672-f89cba46b31f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1_5 = model.fit(\n",
    "    train_set,\n",
    "    epochs=120,\n",
    "    validation_data=validation_set,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ec8a33-4e74-4fb3-9db8-24f58547fd14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize(model1_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f99190-2517-4508-b838-2b8ab4217fb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Model 1_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d585eba9-858f-49d7-98f6-5cb10b321c8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set,validation_set=prep_data(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ab7cb6-a719-48b4-bd64-0498a9b89754",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(180, 180, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.45))\n",
    "model.add(layers.Dense(75 , activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf9f5c8-66eb-4aed-8fc8-9855e11b50a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001), # 0.0002\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f21714-a614-41e4-b2b0-01bbc0877a31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1_5 = model.fit(\n",
    "    train_set,\n",
    "    epochs=100,\n",
    "    validation_data=validation_set,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47319821-4427-4d3f-9452-24962455a4a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize(model1_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadfb414-3626-4bf7-bb31-39581d718db4",
   "metadata": {},
   "source": [
    "#### Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d17862-5aee-4cc2-bd53-8f6656af68ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# importing pretrained models \n",
    "# importing pretrained models \n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications import Xception"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073a6f9f-519b-4d40-8733-089d8a15858d",
   "metadata": {},
   "source": [
    "#### Inception V3 Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec269c7-88c5-460a-b58e-cc66aafed75e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set,validation_set=prep_data(True,batch_size=16) # with Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4385df7-5376-4eb8-a6ed-61924b77fbb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model = InceptionV3(weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(180, 180, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4408fb-0b53-4d56-83bd-ec5300b3b930",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Freeze the layers except the last few layers\n",
    "for layer in base_model.layers[:-15]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e834309e-25ca-4104-83ac-86d29a848850",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(75, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.00005), \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccd769b-eb15-47a2-9302-cce01d5a41fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fine_tune_inception1_1 = model.fit(\n",
    "    train_set,\n",
    "    epochs=40,\n",
    "    validation_data=validation_set,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b1cd37-2ac3-479a-8d8a-df0321da66f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize(fine_tune_inception1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817eff92-550d-4145-94d9-9c56f73021ac",
   "metadata": {},
   "source": [
    "#### Inception V3 Fine Tuning 1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6243d5a3-4769-455a-bcda-8a4dda4a27d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set,validation_set=prep_data(True,batch_size=16) # with Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428d8f63-cf4a-432f-8dd7-d79e088ba17d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model = InceptionV3(weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(180, 180, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f29070-f3ae-42b9-9084-2b2eb0422dbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Freeze the layers except the last few layers\n",
    "for layer in base_model.layers[:-18]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e631e1e-f278-4e26-a3b3-cd788aabac9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(90, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.00005),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c98c83d-b5fd-4022-bb46-398aa80965a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fine_tune_inception1_2 = model.fit(\n",
    "    train_set,\n",
    "    epochs=30,\n",
    "    validation_data=validation_set,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9f23c9-8197-4fe2-b141-bf0150f9d2d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize(fine_tune_inception1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0209a210-9806-43d7-ad66-822e632a6892",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
